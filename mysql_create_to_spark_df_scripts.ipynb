{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert MySQL Create Table to PySpark CreateDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example MySQL Create scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"-- Create syntax for TABLE 'atable'\",\n",
       " 'CREATE TABLE `atable` (',\n",
       " '  `id` bigint(20) NOT NULL AUTO_INCREMENT,',\n",
       " \"  `anotherid` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `thirdid` int(11) NOT NULL DEFAULT '0',\",\n",
       " '  `timestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,',\n",
       " '  `fourthid` int(11) DEFAULT NULL,',\n",
       " '  PRIMARY KEY (`anotherid`),',\n",
       " ') ENGINE=InnoDB AUTO_INCREMENT=BIGNUM DEFAULT CHARSET=utf8;',\n",
       " \"-- Create syntax for TABLE 'btable'\",\n",
       " 'CREATE TABLE `btable` (',\n",
       " '  `btableid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,',\n",
       " \"  `id` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `fifthid` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `type` int(4) NOT NULL DEFAULT '0',\",\n",
       " '  `day` date DEFAULT NULL,',\n",
       " ') ENGINE=InnoDB AUTO_INCREMENT=3170072820 DEFAULT CHARSET=utf8',\n",
       " '/*!50100 PARTITION BY HASH (districtid)',\n",
       " 'PARTITIONS 100 */;']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysql_script = \"\"\"\n",
    "-- Create syntax for TABLE 'atable'\n",
    "CREATE TABLE `atable` (\n",
    "  `id` bigint(20) NOT NULL AUTO_INCREMENT,\n",
    "  `anotherid` int(11) NOT NULL DEFAULT '0',\n",
    "  `thirdid` int(11) NOT NULL DEFAULT '0',\n",
    "  `timestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n",
    "  `fourthid` int(11) DEFAULT NULL,\n",
    "  PRIMARY KEY (`anotherid`),\n",
    ") ENGINE=InnoDB AUTO_INCREMENT=BIGNUM DEFAULT CHARSET=utf8;\n",
    "\n",
    "-- Create syntax for TABLE 'btable'\n",
    "CREATE TABLE `btable` (\n",
    "  `btableid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,\n",
    "  `id` int(11) NOT NULL DEFAULT '0',\n",
    "  `fifthid` int(11) NOT NULL DEFAULT '0',\n",
    "  `type` int(4) NOT NULL DEFAULT '0',\n",
    "  `day` date DEFAULT NULL,\n",
    ") ENGINE=InnoDB AUTO_INCREMENT=3170072820 DEFAULT CHARSET=utf8\n",
    "/*!50100 PARTITION BY HASH (districtid)\n",
    "PARTITIONS 100 */;\n",
    "\"\"\"\n",
    "script = [x for x in mysql_script.split(\"\\n\") if x !=\"\"]\n",
    "script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get rid of comment lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CREATE TABLE `atable` (',\n",
       " '  `id` bigint(20) NOT NULL AUTO_INCREMENT,',\n",
       " \"  `anotherid` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `thirdid` int(11) NOT NULL DEFAULT '0',\",\n",
       " '  `timestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,',\n",
       " '  `fourthid` int(11) DEFAULT NULL,',\n",
       " '  PRIMARY KEY (`anotherid`),',\n",
       " ') ENGINE=InnoDB AUTO_INCREMENT=BIGNUM DEFAULT CHARSET=utf8;',\n",
       " 'CREATE TABLE `btable` (',\n",
       " '  `btableid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,',\n",
       " \"  `id` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `fifthid` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `type` int(4) NOT NULL DEFAULT '0',\",\n",
       " '  `day` date DEFAULT NULL,',\n",
       " ') ENGINE=InnoDB AUTO_INCREMENT=3170072820 DEFAULT CHARSET=utf8',\n",
       " '/*!50100 PARTITION BY HASH (districtid)',\n",
       " 'PARTITIONS 100 */;']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def filter_comments(text, snippet=\"--\"):\n",
    "    return [x for x in text if re.findall(snippet,x)!=[snippet]]\n",
    "filter_comments(script,\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CREATE TABLE `atable` (',\n",
       " '  `id` bigint(20) NOT NULL AUTO_INCREMENT,',\n",
       " \"  `anotherid` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `thirdid` int(11) NOT NULL DEFAULT '0',\",\n",
       " '  `timestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,',\n",
       " '  `fourthid` int(11) DEFAULT NULL,',\n",
       " '  PRIMARY KEY (`anotherid`),',\n",
       " ') ENGINE=InnoDB AUTO_INCREMENT=BIGNUM DEFAULT CHARSET=utf8;',\n",
       " 'CREATE TABLE `btable` (',\n",
       " '  `btableid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,',\n",
       " \"  `id` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `fifthid` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `type` int(4) NOT NULL DEFAULT '0',\",\n",
       " '  `day` date DEFAULT NULL,',\n",
       " ') ENGINE=InnoDB AUTO_INCREMENT=3170072820 DEFAULT CHARSET=utf8',\n",
       " '/*!50100 PARTITION BY HASH (districtid)',\n",
       " 'PARTITIONS 100 */;']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_comment=filter_comments(script,\"--\")\n",
    "no_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if any preamble text get rid of it, start with first CREATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CREATE TABLE `atable` (',\n",
       " '  `id` bigint(20) NOT NULL AUTO_INCREMENT,',\n",
       " \"  `anotherid` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `thirdid` int(11) NOT NULL DEFAULT '0',\",\n",
       " '  `timestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,',\n",
       " '  `fourthid` int(11) DEFAULT NULL,',\n",
       " '  PRIMARY KEY (`anotherid`),',\n",
       " ') ENGINE=InnoDB AUTO_INCREMENT=BIGNUM DEFAULT CHARSET=utf8;',\n",
       " 'CREATE TABLE `btable` (',\n",
       " '  `btableid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,',\n",
       " \"  `id` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `fifthid` int(11) NOT NULL DEFAULT '0',\",\n",
       " \"  `type` int(4) NOT NULL DEFAULT '0',\",\n",
       " '  `day` date DEFAULT NULL,',\n",
       " ') ENGINE=InnoDB AUTO_INCREMENT=3170072820 DEFAULT CHARSET=utf8',\n",
       " '/*!50100 PARTITION BY HASH (districtid)',\n",
       " 'PARTITIONS 100 */;']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_first_create(text,snippet):\n",
    "    return [i for i,x in enumerate(text) if re.search(snippet, x) is not None][0] \n",
    "    \n",
    "create_tabs = no_comment[find_first_create(no_comment, \"CREATE\"):]\n",
    "create_tabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if code read in with readlines, then list needs to be pasted together, else if already text, just return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE TABLE `atable` (  `id` bigint(20) NOT NULL AUTO_INCREMENT,  `anotherid` int(11) NOT NULL DEFAULT '0',  `thirdid` int(11) NOT NULL DEFAULT '0',  `timestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,  `fourthid` int(11) DEFAULT NULL,  PRIMARY KEY (`anotherid`),) ENGINE=InnoDB AUTO_INCREMENT=BIGNUM DEFAULT CHARSET=utf8;CREATE TABLE `btable` (  `btableid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,  `id` int(11) NOT NULL DEFAULT '0',  `fifthid` int(11) NOT NULL DEFAULT '0',  `type` int(4) NOT NULL DEFAULT '0',  `day` date DEFAULT NULL,) ENGINE=InnoDB AUTO_INCREMENT=3170072820 DEFAULT CHARSET=utf8/*!50100 PARTITION BY HASH (districtid)PARTITIONS 100 */;\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def str_type_check(obj):\n",
    "    if type(obj)==list:\n",
    "        return \"\".join(obj)\n",
    "    else: return obj\n",
    "    \n",
    "str_type_check(create_tabs)   # example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse, tables/vars return as dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'`atable`': ['`id` bigint(20) NOT NULL AUTO_INCREMENT',\n",
       "  \"`anotherid` int(11) NOT NULL DEFAULT '0'\",\n",
       "  \"`thirdid` int(11) NOT NULL DEFAULT '0'\",\n",
       "  '`timestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP',\n",
       "  '`fourthid` int(11) DEFAULT NULL'],\n",
       " '`btable`': ['`btableid` bigint(20) unsigned NOT NULL AUTO_INCREMENT',\n",
       "  \"`id` int(11) NOT NULL DEFAULT '0'\",\n",
       "  \"`fifthid` int(11) NOT NULL DEFAULT '0'\",\n",
       "  \"`type` int(4) NOT NULL DEFAULT '0'\",\n",
       "  '`day` date DEFAULT NULL,) ENGINE=InnoDB AUTO_INCREMENT=3170072820 DEFAULT CHARSET=utf8/*!50100 PARTITION BY HASH (districtid)PARTITIONS 100 */']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "def create_table_to_dict(multi_text):\n",
    "    multi_text=str_type_check(multi_text)\n",
    "    sq = re.sub(r\"CREATE TABLE `\",\"`\" ,multi_text.replace(\"\\n\",\"\"))\n",
    "    sq = [s for s in sq.split(\";\") if s is not '']\n",
    "    q_list= [re.sub(',  PRIMARY.*','',q) for q in sq ]\n",
    "    q_dict = {l[0]:l[1].strip() for l in [q.split(\" ( \")  for q in q_list ]}\n",
    "    return {k:v.split(r\",  \") for k,v in q_dict.items()}\n",
    "\n",
    "create_table_to_dict(create_tabs)   # example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take dict and return as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tables</th>\n",
       "      <th>types</th>\n",
       "      <th>vars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>btable</td>\n",
       "      <td>bigint</td>\n",
       "      <td>btableid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>btable</td>\n",
       "      <td>int</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>btable</td>\n",
       "      <td>int</td>\n",
       "      <td>fifthid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>btable</td>\n",
       "      <td>int</td>\n",
       "      <td>type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>btable</td>\n",
       "      <td>date</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>atable</td>\n",
       "      <td>bigint</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>atable</td>\n",
       "      <td>int</td>\n",
       "      <td>anotherid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>atable</td>\n",
       "      <td>int</td>\n",
       "      <td>thirdid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>atable</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>timestamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atable</td>\n",
       "      <td>int</td>\n",
       "      <td>fourthid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tables      types       vars\n",
       "0  btable     bigint   btableid\n",
       "1  btable        int         id\n",
       "2  btable        int    fifthid\n",
       "3  btable        int       type\n",
       "4  btable       date        day\n",
       "5  atable     bigint         id\n",
       "6  atable        int  anotherid\n",
       "7  atable        int    thirdid\n",
       "8  atable  timestamp  timestamp\n",
       "9  atable        int   fourthid"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_to_df(dic_list):\n",
    "\n",
    "  ky = []\n",
    "  vl = []\n",
    "  ty = []\n",
    "  for k,v in dic_list.items():\n",
    "    for x in v:\n",
    "        xx = x.split(\" \")[0:2]\n",
    "        vl.append(xx[0].replace(\"`\",\"\"))\n",
    "        ty.append(xx[1].split(\"(\")[0])\n",
    "        ky.append(k.replace(\"`\",\"\"))\n",
    "\n",
    "  return pd.DataFrame({\"tables\":ky,\"vars\":vl, \"types\":ty})\n",
    "\n",
    "def sql_to_spark(multi_text):\n",
    "  dict_out =create_table_to_dict(multi_text)\n",
    "  return dict_to_df(dict_out)\n",
    "\n",
    "create_df = sql_to_spark(create_tabs) \n",
    "create_df # example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handle wrapping vars in type-casting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float(real_num)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cast_parse(type_str,var_str):\n",
    "    if \"int\" in type_str:\n",
    "        return \"int(\"+var_str+\")\"\n",
    "    elif \"float\" in type_str:\n",
    "        return \"float(\"+var_str+\")\"\n",
    "    elif \"time\" in type_str:\n",
    "        return \"parse(\"+var_str+\")\"\n",
    "    elif \"date\" in type_str :\n",
    "        return \"parse(\"+var_str+\")\"\n",
    "    else : #str_reg.search(type_str)\n",
    "        return var_str\n",
    "cast_parse(\"float\", \"real_num\")  # example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wondering below how I've handled enumerate, zip, and groupby to manage list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'var1=float(p[0]), var2=parse(p[1])'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def col_splitter(colnames,coltypes):\n",
    "    return \", \".join(\n",
    "        [v[0]+'='+ cast_parse(v[1],'p['+str(i)+']')\n",
    "         for i,v in enumerate(zip(colnames, coltypes))] )  # is this best way?\n",
    "\n",
    "names = [\"var1\", \"var2\"]\n",
    "types = ['float', 'timestamp']\n",
    "\n",
    "col_splitter(names, types)    # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['var1', 'var2']\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def col_orderer(colnames):\n",
    "    return str([str(t) for t in colnames])\n",
    "\n",
    "col_orderer(names)  # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_name(data, delimiter=\",\" ):\n",
    "    \n",
    "    # handle either data as sql script \n",
    "    # or already parsed sql script as pandas df\n",
    "    if \"pandas\" in str(type(data)):\n",
    "        df_tables = data\n",
    "    else:\n",
    "        df_tables = sql_to_spark(data)\n",
    "        \n",
    "    row_splitter = \".map(lambda k: k.split('\"+delimiter+\"'))\"\n",
    "    \n",
    "    d={k: \".map(lambda p: Row(\" + \n",
    "           col_splitter(v.vars,v.types) +\n",
    "               \")))[\" + \n",
    "           col_orderer(v.vars) + \"]\"\n",
    "       for k,v in df_tables.groupby(\"tables\")}    ### is this best way?\n",
    "    \n",
    "    return [k+\"_df = sqlContext.createDataFrame(\" +\n",
    "            k + \"_rdd\" + row_splitter + p \n",
    "            for k,p in zip(d.keys(),d.values())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desired pyspark createDataFrame commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"btable_df = sqlContext.createDataFrame(btable_rdd.map(lambda k: k.split(',')).map(lambda p: Row(btableid=int(p[0]), id=int(p[1]), fifthid=int(p[2]), type=int(p[3]), day=parse(p[4]))))[['btableid', 'id', 'fifthid', 'type', 'day']]\",\n",
       " \"atable_df = sqlContext.createDataFrame(atable_rdd.map(lambda k: k.split(',')).map(lambda p: Row(id=int(p[0]), anotherid=int(p[1]), thirdid=int(p[2]), timestamp=parse(p[3]), fourthid=int(p[4]))))[['id', 'anotherid', 'thirdid', 'timestamp', 'fourthid']]\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_name(create_tabs) # ALSO FINE WITH         split_name(create_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"btable_df = sqlContext.createDataFrame(btable_rdd.map(lambda k: k.split(',')).map(lambda p: Row(btableid=int(p[0]), id=int(p[1]), fifthid=int(p[2]), type=int(p[3]), day=parse(p[4]))))[['btableid', 'id', 'fifthid', 'type', 'day']]\",\n",
       " \"atable_df = sqlContext.createDataFrame(atable_rdd.map(lambda k: k.split(',')).map(lambda p: Row(id=int(p[0]), anotherid=int(p[1]), thirdid=int(p[2]), timestamp=parse(p[3]), fourthid=int(p[4]))))[['id', 'anotherid', 'thirdid', 'timestamp', 'fourthid']]\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_name(create_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
